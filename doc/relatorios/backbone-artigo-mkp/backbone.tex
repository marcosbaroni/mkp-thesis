\documentclass{article}

\usepackage{amsmath}

\title{A computational analysis of the multidimensional knapsack problem: a backbone}
\author{Marcos Daniel Baroni}

\begin{document}

% Algorithms to introduce
% - EXACT: Boussier 2010 / Branch-and-cut (CPLEX)
% - DPROG: Bertsimas 2002
% - PROBL: Dyer 1989
% - HEURI: Fleszar 2009
%
% Instances:
% - OR-Library
% - Uniform[0-1]
% - Transformation from other NP-Complete problems (???)
%
% Research questions (what i hope to find out):
% - Which instances are hard/easy for each algorithm?
%   - Why are they hard?
% - Which instances are hard for all algorithms?
%   - Why are they hard for all?
% - Instances from other NP-Complete problems are hard?
%   - What happens with their transition phases.

\maketitle

\begin{abstract}
This article contains a backbone for an in proceeding article about the
hardness of the Multidimensional Knapsack Problem and the performance of
the algorithms existing on literature for its solution.
\end{abstract}

\section{Introduction}
\label{intro}

% Organização das seções:
%  - Seção 2 : Últimos algoritmos propostos
%  - Seção 3 :
%    - comentário sobre instâncias
%    - criação de instâncias difíceis
%    - as instâncias existentes e resultados até então.
%  - Seção 4 : Dúvidas e de pesquisa

% Definição do problema e aplicações
The 0-1 Multidimensional Knapsack Problem (MKP) is a generalization of the Knapsack
Problem where an item expends more than a single resource type.
A MKP having $n$ items and $m$ dimensions can be defined as following:

\begin{align*}
  \text{maximize} & \sum_{j=1}^n p_j x_j \\
  \text{subject to} & \sum_{j=1}^n c_{ij} x_j \leq b_i \quad i \in \{1, \ldots, m\}\\
   & x_j \in \{0, 1\}, \quad j \in \{1, \ldots, n\}.
\end{align*}

The problem can be applied on budget planning scenarios, subset project
selections, cutting stock problems, task scheduling and allocation of processors
and databases in distributed computer programs.
The problem is a generalization of the well-known Knapsack Problem (KP) in which
$ m = 1$.
Several algorithms like FPTAS and dynamic programming have been developed for
KP with considerable success.
However the MKP have shown to be an intractable problem for some relative small
instances, especially when $m$ grows.
Indeed little is known about what exactly makes a hard instance.

Several contributions have been made proposing exact, heuristic, approximation
and probabilistic approaches for the MKP.
The purpose of the work is to evaluate the performance the main approaches
presented on literature over different instances of the problem
identifying what makes an instance hard to solve for the proposed algorithms.

\section{The main approaches for solving MKP}
\label{algs}
Due its simple definition and challenging difficulty, the MKP
turned a quite addressed problem for experiments with metaheuristics in recent
years, although few of them have exhibit competitive performance compared to
comercial MIP solvers (at least for the instances addressed by literature).
Among the heuristics reporting competitive performance compared to MIP solvers
the newest are those proposed by Fleszar and Hindi \cite{fleszar2009fast}
and Hanafi and Wilbaut \cite{hanafi2011improved}.

According to literature MKP does not allow a FPTAS (unless $P=NP$) but a PTAS
was proposed by Frieze and Clarke \cite{frieze1984approximation} based on the
used of the dual simplex algorithm for linear programming.
Dyer and Frieze \cite{dyer1989probabilistic} proposed a probabilistic algorithm
which, given a $\epsilon > 0$ answers computes the optimal solution for the
problem with probability at least $1 - \epsilon$ with polynomial time.

At the present moment the most powerful exact method for solving the MKP seems
to be the multi-level search strategy proposed by Boussier \cite{boussier2010multi}
which, until now, is the only approach which have found the optimal solution for
some popular instances with 500 items and 30 contraints.

\section{The instances}
\label{insts}

The MKP instances from the OR-LIBRARY are the most popular ones and are used
for performance measurement of state-of-art algorithms.
The generation of thoses instances are generaly guided by two parameters: the
profit-weight {\it correlation} of the items and the {\it tightness ratio}
$\delta$ of the knapsack.

The profit-weight correlation $\frac{p_j}{\sum^m_{i=1}w_{ij}}$ states how much
an item contributes for the objective function relative to its weight.
A high variation on the items correlation tends to procude easier instances, once
it easier to decide which items are more profitable.

The tightness ratio of a knapsack rules its relative capacity:
given a tightness ratio $\delta \in [0,1]$ the capacity $b_i$ is setted to
$b_i = \delta \sum_{i=1}^n x_i$. 
An extremaly high tightness ratio tends to produce easy instances, once we
are able to fill the knapsack with most of the items.
However extremaly low tightness ratios reduces the possibilities of filling the
knapsack.
Those facts lead us to expect a {\it transition phase} around $ \delta = 0.5$.

% - OR-Library \cite{Chu-Beasley-1998} (\cite{freville1994efficient})
% - Uniform[0-1] (Dyer 1989) \cite{dyer1989probabilistic}
% - Transformation from other NP-Complete problems \cite{magazine1984note}, ...
% - large dimensions (K.n = m?)
% - Sparse weights

\section{Research questions}
\label{questions}

The main objective of the work is to understand what makes a MKP instance hard
to solve.
Some questions that may be interesting to answer:
\begin{itemize}
  \item{How the hardness of the problem varies against parameters like
    tightness ratio and item correlation?}
  \item{How the algorithms for solving MKP performes over instances from
    others NP-Complete problems?}
  \item{A MKP instance is hard even with sparce weight matrices?}
  \item{For what amount of computational effort the heuristics outperforms
    exact algorithms?}
  \item{Does the PTAS and probabilistic methods (in practice) offer
    better warranty than the exact method or the later indeed offers a better
	warranty on quality which is merely theoretically hard to prove?}
\end{itemize}

\bibliographystyle{abbrv}
\bibliography{../../refs}

\end{document}

