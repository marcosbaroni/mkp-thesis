\documentclass{article}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[linesnumbered,lined,ruled]{algorithm2e}
\usepackage[skip=2pt,labelfont=bf]{caption}

\newtheorem{mydef}{Definition}
\let\emph\textbf

\title{Report...}
\author{Marcos Daniel Baroni}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Objetivo: Apresentar resumidamente os resultados dos testes que fiz sobre
%  tempo esperado do backtrack para o KP;
%  - Comentar sobre artigos:
%    - [1] "On the avrg diff between the solutions to LP and IP KPs"; (comentário, qualidade de solução)
%    - [2] "On finding the Exact Solution of 0-1 KP";
%    - [3] "Random KP in Expected PTime";
%  (- Lembrar que KP:
%     1. é NP-Completo para coeficientes ilimitados;
%     2. admite FPTAS em número de itens;)
%  - Apresentar o algoritmo backtrack para o KP;
%  - Apresentar algoritmo de Programação Dinâmica 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Seção 1: O KP (FPTAS, NP-Completeness, polinomial expectance, )
%    Definição do problema/relaxação LP;
%    Algoritmo Greedy para a relaxação e diferença entre soluções [1];
% Seção 2: O algoritmo de backtrack ()
%    Apresentação 
% Seção 3: O algoritmo de Prog. Dinamica de Beier
% Seção 4: Resultados
%    *Curva1: Nós abertos até encontrar a melhor (polinomial);
%    *Curva2: Nós abertos até provar a melhor (conjectura: 1.8^(x-3) );
%    [2] Citar probabilidade de encontrar a melhor solução;
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle



\begin{align*}
  \text{maximize} & \sum_{j=1}^n p_j x_j \\
  \text{subject to} & \sum_{j=1}^n w_j x_j \leq b \\
   & x_j \in \{0, 1\}, \quad j \in \{1, \ldots, n\}.
\end{align*}

\section{}

\section{The Backtracking Approach}
\cite{lueker1998average}
\cite{horowitz1978fundamentals}

\begin{displaymath}
  \frac{p_1}{w_1} \geqslant
  \frac{p_2}{w_2} \geqslant
  \ldots \geqslant
  \frac{p_n}{w_n}
\end{displaymath}

\newpage

\section{The Nemhauser-Ullmann Algorithm}

A brute force method to solve the knapsack problem is to enumerate all possible subsets over the $n$ items.
In order to reduce the search space, a domination concept is used which is usually attributed to Weingartner and Ness~\cite{weingartner1967methods}.
\begin{mydef}[Domination]
A subset $S \in [n]$ with weight $w(S) = \sum_{i \in S} w_i$  and profit $p(S) = \sum_{i \in S} p_i$
\emph{dominates} another subset $T \subseteq [n]$ if $w(S) \leqslant w(T)$ and $p(S) \geqslant p(T)$.
\end{mydef}

For simplicity assume that no two subsets have the same profit.
Then no subset dominated by another subset can be an optimal solution to the knapsack problem, regardless of the specified knapsack capacity.
Consequently, it suffices to consider those sets that are not dominated by any other set.

Using this concept Nemhauser and Ullmann~\cite{nemhauser1969discrete} introduced an elegant
algorithm (Algorithm~\ref{alg:nu}) computing a list of all dominating sets in an iterative manner.

\begin{algorithm}[H]
 \SetKwInOut{Input}{Input}
 \SetKwInOut{Output}{Output}
 \Input{a KP instance}
 \Output{list $S(n)$ of all dominating sets}
 $S(0) \leftarrow \emptyset $\;
 \For{$i\leftarrow 1$ \KwTo $n$}{
   $S'(i) \leftarrow S(i-1)\; \cup \big\{ s \cup \{i\} \,\big|\, s \in S(i-1)\big\}$\;
   %$S(i) \leftarrow \big\{ s \,\big|\, s \in S'(i), dominates\big(s, S'(i)\big) \big\}$\;
   $S(i) \leftarrow \big\{ s \in S'(i) \,\big|\, dominates\big(s, S'(i)\big) \big\}$\;
   %$S(i) \leftarrow \emptyset $\;
   %\ForEach{$ s \in S'(i)$}{
   %   \If{$ dominates\big(s, S'(i)\big)$}{
   %      $S(i) \leftarrow S(i) \cup \{s\}$\;
   %  }
   %}
 }
 \caption{The Nemhauser-Ullmann Algorithm}
 \label{alg:nu}
\end{algorithm}

%Let $S(i)$ be the sequence of dominating subsets over the items $1, \ldots, i$.
%Given $S(i-1)$, the sequence $S(i)$ can be computed as follows:
%Now we compute $S(i)$ by selecting just the dominating sets in $S'(i)$ (line 4).
This algorithm can be viewed as a sparse dynamic programming approach which,
at each iteration duplicates all subsets in $S(i-1)$ and then adds item $i$
to each of the duplicated subsets (line 3).
The $dominates(s, S)$ procedure checks if subset $s$ dominates all others subsets in $S$.
The dominated subsets are then {\it filtered} (line 4).
The result is the ordered sequence $S(n)$ of dominating subsets over the items $1, \ldots, n$.

Figure~\ref{fig:pareto} graphically represents profit and weight values for
dominating sets of (a) an intermediate solution $S(i)$,
(b) its next solution $S(i+1)$ and (c) an optimal solution for a small random instance.

If we denote $q(i)$ the upper bound on the number of dominating sets over items in
$1, \ldots, i$, at each iteration the algorithm computes $S(i)$ over $S(i-1)$ in $O\big(q(i)\big)$ time.
The total running time of the algorithm is then $O\big(n \cdot q(n)\big)$.
Now the challenge in the analysis is to estimate the number of dominating sets.

Beier and V{\"o}cking~\cite{beier2003random} addressed this analysis considering
sets of items with adversary weights and randomly drawn profits.
They could deduce that for the uniform distribution, for example, the expected
number of dominating sets is $E[q] = O(n^3)$ leading to an expected running
time of $O(n^4)$.

\begin{figure}
  \includegraphics[width=\textwidth]{pareto}
  \caption{Graphical representation of dominating sets for
  (a) an intermediate solution $S(i)$, (b) its next solution $S(i+1)$. and
  (c) an optimal solution for a small random instance.}
  \label{fig:pareto}
\end{figure}

\bibliographystyle{abbrv}
\bibliography{../../refs}

\end{document}

