% Breve resumo sobre métodos de programação dynamica
% Explicação overview do método para o MOKP
% - Process overview of DP for MKP
% - Dom. relations
% - Application of dom. rel.

\missing{Paragrafo de introducao da secao, justificando toda a explicacao que segue..}

The dynamic programming algorithm is based on the classical Nemhauser-Ullmann (NU) algorithm proposed
in \cite{nemhauser1969discrete}.
concept of domination for knapsack problems,
proposed by Weingartner and Ness~\cite{weingartner1967methods}.

Some property of the MOKP will be explored...
three filter as optimizations for the trying
to reduce the number of solutions
handled on mid stages of the algorithm...
We will introduce the dynamic programming (DP) algorithm for the MOKP proposed in \cite{bazgan2009}.

%\subsection{Definitions}

\subsection{The NU algorithm -- the knapsack dominance}
The knapsack-domination is the concept that mainly driver the algorithm...
The pseudocode for the algorithm is presented in Algorithm~\ref{alg:nemull}.
\begin{algorithm}
  \caption{Basic dynamic programming algorithm for MOKP}
  \label{alg:nemull}
  \input{src/algs/dp1.tex}
\end{algorithm}
At the $k$-th stage the algorithm receives a set $S^{k-1}$ of solutions and
generates the set $S^k$ of solutions that correspond
to subsets containing exclusively the first $k$ items, i.e.\,,
$\forall\sol{x} \in S^k, \sol{x} \subseteq \{1, \ldots, k\}$.

This is done by expanding $S^{k-1}$ by adding a copy of each solution with the
inclusion of $k$-th item (line 4).
We will refer as \emph{partial solutions} all the solutions handled by
stages prior to $n$-th stage.

The clever part of the algorithm is that it uses the concept of knapsack dominance
to filter solutions that will not lead to efficient solutions (line 5).
Considering two partial solutions $\sol{x}, \sol{y} \in S^k$, if
$\sol{x}$ is knapsack-dominated by $\sol{y}$ then we may discard $\sol{x}$ since all
solutions generated from $\sol{x}$ will be dominated by those generated from $\sol{y}$.

\subsection{Item order}

\subsection{Avoiding deficient solutions}

The first optimization that can be made on Algorithm~\ref{alg:nemull} is
avoiding the generation of deficient solutions.
At $k$-th stage all previous solution is copied to the
new solution set without adding $k$-th item (line 4).
However preserving solutions with a lot of space left, concerning the remaining itens,
may lead to deficient solutions.

\begin{theorem}
   Considering the $k$-th stage of the algorithm and $\sol{x} \in S^{k-1}$.
   If $\weight{x} + \sum_{i \in {\{k, \ldots, n\}}} w_i \leq W$ than
\end{theorem}

Considering the $k$-th stage, if a partial solution $\sol{x} \in S^{k-1}$ has enough
space to fit all remaining items, i.e.\,, $\weight{x} + \sum_{i=k}^n w_i \leq W$,
$\sol{x}$ may be discarded and only $\sol{x} \cup \{k\}$ keeped, once
keeping $\sol{x}$ will certainly lead to deficient solutions.

\subsection{Removing unpromissing solutions}

Another optimization that can be applied on later stages is
filtering unpromissing solutions by computing upper bounds for its objectives
functions and comparing it with the set of available lower bounds.
An upper(lower) bound of a solution is an upper(lower) limit each objective
value can achieve given its remaining capacity and the remaining items.
If the upper bound of a solution is dominated by an existing lower bound,
that solution can be discarded since it will not generate an efficient solution.

A lower bound of a solution can be easily computed...

Formally:
\begin{align*}
    lb(\sol{x}, \sol{s}) &= \sol{x} \cup
      %\bigg\{ o_i \;\bigg|\; \weight{x} + \sum_{j=1}^i w_{o_j} \leq W \bigg\} \\
      \big\{ o_i \;\big|\; \weight{x} + \textstyle\sum_{j=1}^i w_{o_j} \leq W \big\} \\
  \text{where} \phantom{mmmmm} \\
    (o_1, \ldots, o_k) &= O_{max}(\sol{s}) \\
\end{align*}

An upper bound of a solution can be easily computed...

Formally:
\begin{align*}
    ub(\sol{x}, \sol{S}) &= \big(ub_1(\sol{x}, \sol{S}), \ldots, ub_\np(\sol{x}, \sol{S})\big) \\
      %\bigg\{ o_i \;\bigg|\; \weight{x} + \sum_{j=1}^i w_{o_j} \leq W \bigg\} \\
    ub_i(\sol{x}, \sol{s}) &= f_i(\sol{x}) + \textstyle\sum^r_{j=1} p^i_{o^i_j} + t.p^i_{o^i_{r+1}}\\
  \text{where} \phantom{mmmmm} \\
    (o_1, \ldots, o_k) &= O_{cb}^i(\sol{S}) \\
    r &= max\big( j \;\big|\; \weight{x} + \textstyle\sum_{l = 1}^j w_{o^i_l} \leq W \big) \\
    t &= \textstyle
\end{align*}

\begin{algorithm}
  \caption{Upper-bound computation for a partial solution.}
  \label{alg:up}
  \begin{algorithmic}[1]
      \Function{UP}{$\sol{p}, \bsym{w}, W, \sol{x}, \sol{S}$}
      \State $w_{left} \gets W - \weight{x}$
      \While{$w_{left} > w_i$}
        % Extension
        \State $2$
      \EndWhile
      \State \Return $\solSet^n$
    \EndFunction
  \end{algorithmic}
\end{algorithm}


\begin{algorithm}
  \caption{Bazgan's DP algorithm for the MOKP}
  \label{alg:bazgan}
  \input{src/algs/dp2.tex}
\end{algorithm}


% Basic simple Dynamic Programming
% Nemhauser-Ullmann algorithm
