% Breve resumo sobre métodos de programação dynamica
% Explicação overview do método para o MOKP
% - Process overview of DP for MKP
% - Dom. relations
% - Application of dom. rel.

\missing{Paragrafo de introducao da secao, justificando toda a explicacao que segue..}

The dynamic programming algorithm is based on the classical Nemhauser-Ullmann (NU) algorithm proposed
in \cite{nemhauser1969discrete}.
concept of domination for knapsack problems,
proposed by Weingartner and Ness~\cite{weingartner1967methods}.

Some property of the MOKP will be explored...
three filter as optimizations for the trying
to reduce the number of solutions
handled on mid stages of the algorithm...
We will introduce the dynamic programming (DP) algorithm for the MOKP proposed in \cite{bazgan2009}.

%\subsection{Definitions}

\subsection{Item ordering}

An important issue in the MOKP is the ordering of items.
It is well-known that good solutions of knapsack problems
are generally composed of items with good profit-weight relation.
Therefore, the prioritization of those items tends to lead to better solutions.

For the multi-objective case however, there is no such natural measure.
The method proposed by~\cite{bazgan2009} will be considered in this work, in which is based on the ranking of items from their cost-benefit measures in the various objectives.
Those measures will give us several items orders which will be useful during the development of the algorithm.

We denote $\ord^j$ the set of items ordered by ascending order of cost-benefit function regarding objective $j$.
Formally, considering the function $\cb{j}{a} = {p^j_a}/{w_a}$ the
cost-benefit function of item $a$ regarding objective $j$, order
$\ord^j$ can be defined by:
\begin{align*}
  \ord^j &= (o^j_1, \ldots, o^j_n) , \qquad \cb{j}{o^j_1} \leq \cb{j}{o^j_2} \leq \cdots \leq \cb{j}{o^j_n}
\end{align*}
Let $r^j_i$ be the rank of item $i$ in order $\ord^j$.
$\ord^{sum}$, $\ord^{min}$ and $\ord^{max}$ denotes an order according to inscreasing values of the sum, minimum and maximum ranks.
Formally:
\begin{align*}
  r^j_i &= \max\{ k \;|\; o^j_k = i \} \\
  r^{sum}_i &= \textstyle\sum^\np_{j=1} r^j_i \\
  \ord^{sum} &= (o_1, \ldots, o_n) , \qquad r^{sum}_{o_1} \leq \cdots \leq r^{sum}_{o_n}
\end{align*}
The orders $\ord^{min}$ and $\ord^{max}$ are conceived in the same manner as
$\ord^{sum}$, except for the fact that $\frac{r^{sum}_i}{\np}$ is added up
in their ranks as tie breaking criteria.
The notation $\ord(\sol{s})$ will be used to denote the respective ordering
of a $\sol{s}$ restrict set of items.


\subsection{Nemhauser-Ullmann algorithm -- the knapsack dominance}

The algorithm considered in this work is based on the Nemhauser-Ullmann algorithm,
a dynamic programming method for knapsack problems, which is presented by Algorithm~\ref{alg:nemull}

\begin{algorithm}
  \caption{Basic dynamic programming algorithm for MOKP}
  \label{alg:nemull}
  \input{src/algs/dp1.tex}
\end{algorithm}

At $k$-th stage the algorithm receives the set $S^{k-1}$ of solutions and
generates the set $S^k$ of solutions that correspond
to subsets containing exclusively the first $k$ items, i.e.\,,
$\forall\sol{x} \in S^k, \sol{x} \subseteq \{1, \ldots, k\}$.

This is done by expanding $S^{k-1}$ by adding a copy of each solution with the
inclusion of $k$-th item (line 4).
We will refer as \emph{partial solutions} all the solutions handled by
stages prior to $n$-th stage.

The clever part of it is that it uses the concept of knapsack dominance
to filter solutions that will not lead to efficient solutions (line 5).
Considering two partial solutions $\sol{x}, \sol{y} \in S^k$, if
$\sol{x}$ is knapsack-dominated by $\sol{y}$ then we may discard $\sol{x}$ since all
solutions generated from $\sol{x}$ will be dominated by those generated from $\sol{y}$.

\subsection{Avoiding deficient solutions}

The first optimization that can be made on Algorithm~\ref{alg:nemull} is
avoiding the generation of deficient solutions.
At $k$-th stage all previous solution is copied to the
new solution set without adding $k$-th item (line 4).
However preserving solutions with a lot of space left, concerning the remaining itens,
may lead to deficient solutions.

\begin{theorem}
   Considering the $k$-th stage of the algorithm and $\sol{x} \in S^{k-1}$.
   If $\weight{x} + \sum_{i \in {\{k, \ldots, n\}}} w_i \leq W$ than
\end{theorem}

Considering the $k$-th stage, if a partial solution $\sol{x} \in S^{k-1}$ has enough
space to fit all remaining items, i.e.\,, $\weight{x} + \sum_{i=k}^n w_i \leq W$,
$\sol{x}$ may be discarded and only $\sol{x} \cup \{k\}$ keeped, once
keeping $\sol{x}$ will certainly lead to deficient solutions.

\subsection{Removing unpromissing solutions}

Another optimization that can be applied on later stages is
filtering unpromissing solutions by computing upper bounds for its objectives
functions and comparing it with the set of available lower bounds.
Considering a given $k$-th iteration, an upper(lower) bound of a partial solution
is an upper(lower) limit each objective value can achieve,
given its remaining capacity and the remaining items $(k+1, \ldots, n)$.
A solution can be discharged if its upper bound is dominated by an existing lower bound, since it will generate no efficient solution.

A lower bound of a solution can be computed by greedily filling the
knapsack with respect to $\ord^{max}$ which is a good quality order of items.
Formally:
\begin{align*}
    &lb(\sol{x}, \sol{s}) = \sol{x} \cup
      %\bigg\{ o_i \;\bigg|\; \weight{x} + \sum_{j=1}^i w_{o_j} \leq W \bigg\} \\
      \left\{ o_i \;\middle|\; \weight{x} + \textstyle\sum_{j=1}^i w_{o_j} \leq W \right\} \\
  \text{where} \phantom{mmmmm} \\
    &(o_1, \ldots, o_k) = \ord^{max}(\sol{s}) \\
\end{align*}

The upper-bound of a partial solution $\sol{x}$ is computed considering
its available capacity and the remaining items on the current algorithm stage.
To ensure the upper-bound its computation is done separately for.
For the each $j$-th objective the reversed order $\ord^j({\sol{s}})$ on
the set $\sol{s}$ of remaining items is considered to iteratively fill the
remaining capacity of $\sol{x}$.
%Formally:
%\begin{gather*}
%    ub(\sol{x}, \sol{s}) = \big(ub_1(\sol{x}, \sol{s}), \ldots, ub_\np(\sol{x}, \sol{s})\big) \\
%      %\bigg\{ o_i \;\bigg|\; \weight{x} + \sum_{j=1}^i w_{o_j} \leq W \bigg\} \\
%    ub_i(\sol{x}, \sol{s}) = f_i(\sol{x}) + \textstyle\sum^t_{j=1} p^i_{o^i_j} + \frac{w_{res}}{w_{o^i_{t+1}}}.p^i_{o^i_{t+1}}\\
%  \text{where} \phantom{mmmmm} \\
%    (o^i_1, \ldots, o^i_k) = \ord^i(\sol{s}) \\
%    t = max\big( j \;\big|\; \weight{x} + \textstyle\sum_{l = 1}^j w_{o^i_l} \leq W \big) \\
%    w_{res} = W - \weight{x} - \sum^t_{j=1}w_{o^i_t}
%\end{gather*}

\begin{algorithm}
  \caption{Upper-bound computation for a partial solution.}
  \label{alg:ub}
  \begin{algorithmic}[1]
      \Function{UB$_j$}{$\sol{p}, \bsym{w}, W, \sol{x}, \sol{s}$}
      \State $w_{left} \gets W - \weight{x}$
      \State $(o^j_1, \ldots, o^j_k) \gets \ord^j(\sol{s})$
      \State $u_j \gets f_j(\sol{x})$
      \State $i \gets 1$
      \State $l \gets o^j_i$
      \While{$w_{left} \geq w_l$ {\bf and} $i \leq k$}
        \State $u_j \gets u_j + p^j_{l}$
        \State $w_{left} \gets w_{left} - w_l$
      \EndWhile
      \If{$i \leq k$}
        \State $l \gets o^j_i$
        \State $u_j \gets u_j + \frac{w_{left}}{w_l}.p^j_{l}$
      \EndIf
      \State \Return $u_j$
    \EndFunction
  \end{algorithmic}
\end{algorithm}


\begin{algorithm}
  \caption{Bazgan's DP algorithm for the MOKP}
  \label{alg:bazgan}
  \input{src/algs/dp2.tex}
\end{algorithm}


% Basic simple Dynamic Programming
% Nemhauser-Ullmann algorithm
