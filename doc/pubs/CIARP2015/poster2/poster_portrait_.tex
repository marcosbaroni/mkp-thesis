\documentclass[portrait,final,a0paper,fontscale=0.277]{baposter}

\usepackage{calc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{relsize}
\usepackage{multirow}
\usepackage{rotating}
\usepackage{bm}
\usepackage{url}
\usepackage[brazil]{babel}   
\usepackage[utf8]{inputenc}  
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{graphicx}
\usepackage{multicol}

%\usepackage{times}
%\usepackage{helvet}
%\usepackage{bookman}
\usepackage{palatino}

\newcommand{\captionfont}{\footnotesize}

%\graphicspath{{images/}{../images/}}
\usetikzlibrary{calc}

\newcommand{\SET}[1]  {\ensuremath{\mathcal{#1}}}
\newcommand{\MAT}[1]  {\ensuremath{\boldsymbol{#1}}}
\newcommand{\VEC}[1]  {\ensuremath{\boldsymbol{#1}}}
\newcommand{\Video}{\SET{V}}
\newcommand{\video}{\VEC{f}}
\newcommand{\track}{x}
\newcommand{\Track}{\SET T}
\newcommand{\LMs}{\SET L}
\newcommand{\lm}{l}
\newcommand{\PosE}{\SET P}
\newcommand{\posE}{\VEC p}
\newcommand{\negE}{\VEC n}
\newcommand{\NegE}{\SET N}
\newcommand{\Occluded}{\SET O}
\newcommand{\occluded}{o}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% Some math symbols used in the text
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Multicol Settings
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\setlength{\columnsep}{1.5em}
\setlength{\columnseprule}{0mm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Save space in lists. Use this after the opening of the list
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\compresslist}{%
\setlength{\itemsep}{1pt}%
\setlength{\parskip}{0pt}%
\setlength{\parsep}{0pt}%
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Begin of Document
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Here starts the poster
%%%---------------------------------------------------------------------------
%%% Format it to your taste with the options
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Define some colors

%\definecolor{lightblue}{cmyk}{0.83,0.24,0,0.12}
\definecolor{lightblue}{rgb}{0.145,0.6666,1}

% Draw a video
\newlength{\FSZ}
\newcommand{\drawvideo}[3]{% [0 0.25 0.5 0.75 1 1.25 1.5]
   \noindent\pgfmathsetlength{\FSZ}{\linewidth/#2}
   \begin{tikzpicture}[outer sep=0pt,inner sep=0pt,x=\FSZ,y=\FSZ]
   \draw[color=lightblue!50!black] (0,0) node[outer sep=0pt,inner sep=0pt,text width=\linewidth,minimum height=0] (video) {\noindent#3};
   \path [fill=lightblue!50!black,line width=0pt] 
     (video.north west) rectangle ([yshift=\FSZ] video.north east) 
    \foreach \x in {1,2,...,#2} {
      {[rounded corners=0.6] ($(video.north west)+(-0.7,0.8)+(\x,0)$) rectangle +(0.4,-0.6)}
    }
;
   \path [fill=lightblue!50!black,line width=0pt] 
     ([yshift=-1\FSZ] video.south west) rectangle (video.south east) 
    \foreach \x in {1,2,...,#2} {
      {[rounded corners=0.6] ($(video.south west)+(-0.7,-0.2)+(\x,0)$) rectangle +(0.4,-0.6)}
    }
;
   \foreach \x in {1,...,#1} {
     \draw[color=lightblue!50!black] ([xshift=\x\linewidth/#1] video.north west) -- ([xshift=\x\linewidth/#1] video.south west);
   }
   \foreach \x in {0,#1} {
     \draw[color=lightblue!50!black] ([xshift=\x\linewidth/#1,yshift=1\FSZ] video.north west) -- ([xshift=\x\linewidth/#1,yshift=-1\FSZ] video.south west);
   }
   \end{tikzpicture}
}

\hyphenation{resolution occlusions}
%%
\begin{poster}%
  % Poster Options
  {
  % Show grid to help with alignment
  grid=false,
  % Column spacing
  colspacing=1em,
  % Color style
  bgColorOne=white,
  bgColorTwo=white,
  borderColor=black,
  headerColorOne={rgb:red,30;green,146;blue,154},
  headerColorTwo={rgb:red,30;green,146;blue,154},
  headerFontColor=white,
  boxColorOne=white,
  boxColorTwo={rgb:red,30;green,146;blue,154},
  % Format of textbox
  textborder=roundedleft,
  % Format of text header
  eyecatcher=true,
  headerborder=closed,
  headerheight=0.1\textheight,
%  textfont=\sc, An example of changing the text font
  headershape=roundedright,
  headershade=shadelr,
  headerfont=\Large\bf\textsc, %Sans Serif
  textfont={\setlength{\parindent}{1.5em}},
  boxshade=plain,
%  background=shade-tb,
  background=plain,
  linewidth=2pt
  }
  % Eye Catcher
  {\includegraphics[height=8em]{imgs/ninfa_logo.png}} 
  % Title
  {\bf\textsc{A shuffled complex evolution algorithm for
the multidimensional knapsack problem}\vspace{0.5em}}
  % Authors
  %{\textsc{\{dluchi,wsantos,arodrigues,fvarejao\}@ninfa.inf.ufes.br}}
  {\textsc{Marcos Baroni & Flávio Varejão}
  % University logo
  {% The makebox allows the title to flow into the logo, this is a hack because of the L shaped logo.
    \includegraphics[height=8.0em]{../../brasao_ufes}
  }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Now define the boxes that make up the poster
%%%---------------------------------------------------------------------------
%%% Each box has a name and can be placed absolutely or relatively.
%%% The only inconvenience is that you can only specify a relative position 
%%% towards an already declared box. So if you have a box attached to the 
%%% bottom, one to the top and a third one which should be in between, you 
%%% have to specify the top and bottom boxes before you specify the middle 
%%% box.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    %
    % A coloured circle useful as a bullet with an adjustably strong filling
    \newcommand{\colouredcircle}{%
      \tikz{\useasboundingbox (-0.2em,-0.32em) rectangle(0.2em,0.32em); \draw[draw=black,fill=lightblue,line width=0.03em] (0,0) circle(0.18em);}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \headerbox{The Multidimensional Knapsack Problem}{name=problem,column=0,row=0}{
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  In many applications of different fields the task of identifying sets of similar elements is required. The concept of similarity is subjective and may vary from one application to another. A widely used and well-known criteria for similarity
  is the sum of squared errors (SSE).
  The $k$-means is a clustering algorithm very well known for its speed and accuracy when the metric to be met is the SSE \cite{kmeans}. However, the traditional $k$-means algorithm is unfeasible for very large data sets.
 }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \headerbox{Objective}{name=contribution,column=0,below=problem}{
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  In this paper we present a sampling approach to run the $k$-means
algorithm on large data sets. We propose a new genetic algorithm
to guide sample selection to yield better results than selecting the individuals at random. We apply our proposal in a public mapping points data set from the 9th DIMACS Implementation Challenge \cite{dimacs}.
  }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\headerbox{Results}{name=results,column=1,span=2,row=0}{
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{center}
\noindent\begin{tabular}{@{\hspace{0.0em}}c@{\hspace{1.0em}}c@{\hspace{0.0em}}}
\includegraphics[width=0.46\linewidth]{images/img/sse_ny.pdf} &
\includegraphics[width=0.46\linewidth]{images/img/sse_col.pdf} 
\\
\includegraphics[width=0.46\linewidth]{images/img/sse_ne.pdf} &
\includegraphics[width=0.46\linewidth]{images/img/sse_nw.pdf} 
\end{tabular}
\end{center}

\begin{multicols}{2}

    We have used twelve real data sets varying from small to very large number of points. They are all mapping points from the 9th DIMACS Implementation Challenge. We have varied it from 2 to 20. Solution quality 1 represents best known solution, obtained by carrying out the full $k$-means (time consuming) algorithm (sample size 512).
\end{multicols}
\vspace{-0.6em}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \headerbox{References}{name=references,column=0,above=bottom}{
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \smaller
    \bibliographystyle{plain}
    \renewcommand{\section}[2]{\vskip 0.05em}
      \begin{thebibliography}{1}\itemsep=-0.01em
      \setlength{\baselineskip}{0.4em}
      \bibitem{dimacs}
        Demetrescu, C. and Goldberg, A. and Johnson, D.
        \newblock 9th DIMACS implementation challenge--Shortest Paths
        \newblock American Mathematical Society, 2006.
      \bibitem{kmeans}
        Jain, Anil K
        \newblock Data clustering: 50 years beyond K-means
        \newblock Pattern recognition letters, 2010.
      \end{thebibliography}
   \vspace{0.0em}
  }
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \headerbox{Genetic Operators}{name=background model,column=1,below=results}{
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The mutation operator removes an element of an individual and choose, from the full dataset, a new element to replace it. However, we introduce a bias in this random selection. This kind of bias does not normally exist, but our tests showed good results. We use a mechanism similar to the selection (roulette wheel), so that the closer to the centroid the greater the probability of being chosen for removal from the sample, since those points contribute little to the SSE.

\begin{algorithmic}
\Function{Mutation}{$ individual $}
\State using roulette wheel selection to select a point from the sample to swap
\State select a random point from the population not in the sample
\State swap the two points
\EndFunction
\end{algorithmic}

\begin{algorithmic}
\Function{Crossover}{$ indv1,indv2 $}
\State $indv1$ $\gets$ \Call{shuffle}{$indv1$}
\State $indv2$ $\gets$ \Call{shuffle}{$indv2$}
\State $cut$ $\gets$ a \Call{random}{$0$,$sampleSize$}
\State newIndv1 $\gets$ elements before the cut of $indv1$ $\cup$ elements after the cut of $indv2$
\State newIndv2 $\gets$ elements before the cut of $indv2$ $\cup$ elements after the cut of $indv1$
\State \Return newIndv1, newIndv2
\EndFunction
\end{algorithmic}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\headerbox{Scalability}{name=speed,column=2,row=0,below=results,bottomaligned=background model}{
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

 \noindent{\centering\includegraphics[width=0.95\linewidth]{images/img/time_ny.pdf}\\}
 
 \noindent{\centering\includegraphics[width=0.95\linewidth]{images/img/time_lks.pdf}\\}

\indent{}The Figures show the comparison of running times of our genetic proposal and the full $k$-means algorithm for the NY and LKS data sets.

As the number of clusters goes up, the time consumed to finish the
$k$-means algorithm increases substantially, whereas the runtime for our proposal scales well (sublinear). 

   \vspace{0.0em}
  }
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \headerbox{Acknowledgement}{name=source,column=2,below=speed,above=bottom}{
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   We gratefully acknowledge the financial support provided by Fundação de Amparo à Pesquisa e Inovação do Espírito Santo (FAPES)\footnote{\url{http://www.fapes.es.gov.br/}}, without
   which the present study could not have been completed.
   \vspace*{0.5em}
  }
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \headerbox{A Future Direction}{name=questions,column=1,span=1,below=background model,above=bottom}{
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \begin{itemize}
    \item  Improve the quality drop when the number.
of clusters goes up (sample size increases linear with $k$).
    \item Compare how this sampling technique performs next to other algorithms for clustering Large Data Sets.
   \end{itemize}
   \vspace{0.3em}
  }
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \headerbox{Method}{name=method,column=0,below=contribution,above=references}{
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \noindent{\centering\includegraphics[width=0.95\linewidth]{images/img/selected.pdf}\\}
  \indent  Our proposal finds the set
of observations that results in the highest sample SSE. 
The intuition behind our approach is that if we remove a point close to a centroid its position will not change significantly. The further from a centroid a point to be removed is, the further the centroid will be repositioned. Therefore points in the cluster edge will have a greater impact on the centroid position and if we want to choose a set of points to remove from the data set, points with less impact on the centroid position (low contribution to SSE) is a good idea.

The basic idea would be to discard points near the centroid and pick up new ones to replace them, keeping the sample size unchanged. After that, run the $k$-means algorithm in the new sample and repeat the procedure with the new centroids. Repeat this until you can not get a higher SSE. The selected points in the last sample must be away from the centroids, on the edge of the clusters.
   \vspace{0.3em}
  }

\end{poster}

\end{document}

